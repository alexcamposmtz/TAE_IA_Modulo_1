{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2868fd54-eecd-47fe-afa7-86281846f5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ECU3.4 - Matrix Multiply Naive (SIMULADOR)\n",
      "Autor: Alejandro Campos Martínez - Team 6\n",
      "======================================================================\n",
      "NOTA: Modo simulador - Tiempos no representan rendimiento real\n",
      "ADVERTENCIA: Este kernel naive es ineficiente por diseño\n",
      "\n",
      "Tamaño de matrices: A(1000x1000) @ B(1000x1000) = C(1000x1000)\n",
      "Total elementos resultado: 1,000,000\n",
      "Operaciones: 1,000,000,000 multiplicaciones\n",
      "Configuración: (63, 63) bloques\n",
      "               (16, 16) threads por bloque\n",
      "----------------------------------------------------------------------\n",
      "Ejecutando kernel...\n",
      "\n",
      "GPU kernel time: 1068407.4998 ms\n",
      "CPU NumPy time: 20.8037 ms\n",
      "Speedup: 0.00x\n",
      "Verificación correcta: True\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ECU3.4 - Matrix Multiply Naive\n",
    "Versión: SIMULADOR (Compatible con Colab y máquinas sin GPU NVIDIA)\n",
    "Team 6\n",
    "Autor: Alejandro Campos Martínez\n",
    "Curso: TAE en IA - COCYTEN Nayarit\n",
    "Propósito: Multiplicación de matrices naive (sin optimizaciones) para demostrar\n",
    "           la importancia de optimizaciones como shared memory\n",
    "\"\"\"\n",
    "import os\n",
    "os.environ[\"NUMBA_ENABLE_CUDASIM\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "from numba import config\n",
    "\n",
    "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
    "\n",
    "@cuda.jit\n",
    "def matmul_naive_kernel(A, B, C):\n",
    "    \"\"\"\n",
    "    Naive matrix multiply: C = A @ B\n",
    "    Each thread computes one element of C.\n",
    "    \"\"\"\n",
    "    row, col = cuda.grid(2)\n",
    "\n",
    "    M, K = A.shape\n",
    "    K2, N = B.shape\n",
    "\n",
    "    if row < M and col < N:\n",
    "        total = 0.0\n",
    "        for k in range(K):\n",
    "            total += A[row, k] * B[k, col]\n",
    "        C[row, col] = total\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ECU3.4 - Matrix Multiply Naive (SIMULADOR)\")\n",
    "    print(\"Autor: Alejandro Campos Martínez - Team 6\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"NOTA: Modo simulador - Tiempos no representan rendimiento real\")\n",
    "    print(\"ADVERTENCIA: Este kernel naive es ineficiente por diseño\\n\")\n",
    "    \n",
    "    M, K, N = 1000, 1000, 1000\n",
    "    print(f\"Tamaño de matrices: A({M}x{K}) @ B({K}x{N}) = C({M}x{N})\")\n",
    "    print(f\"Total elementos resultado: {M*N:,}\")\n",
    "    print(f\"Operaciones: {M*N*K:,} multiplicaciones\")\n",
    "    \n",
    "    A = np.random.randn(M, K).astype(np.float32)\n",
    "    B = np.random.randn(K, N).astype(np.float32)\n",
    "    C = np.zeros((M, N), dtype=np.float32)\n",
    "\n",
    "    threads_per_block = (16, 16)\n",
    "    d_A = cuda.to_device(A)\n",
    "    d_B = cuda.to_device(B)\n",
    "    d_C = cuda.to_device(C)\n",
    "\n",
    "    blocks_per_grid_x = (M + threads_per_block[0] - 1) // threads_per_block[0]\n",
    "    blocks_per_grid_y = (N + threads_per_block[1] - 1) // threads_per_block[1]\n",
    "    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "    \n",
    "    print(f\"Configuración: ({blocks_per_grid_x}, {blocks_per_grid_y}) bloques\")\n",
    "    print(f\"               ({threads_per_block[0]}, {threads_per_block[1]}) threads por bloque\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    # Warmup\n",
    "    matmul_naive_kernel[blocks_per_grid, threads_per_block](d_A, d_B, d_C)\n",
    "    cuda.synchronize()\n",
    "\n",
    "    # GPU timing\n",
    "    print(\"Ejecutando kernel...\")\n",
    "    start = time.time()\n",
    "    matmul_naive_kernel[blocks_per_grid, threads_per_block](d_A, d_B, d_C)\n",
    "    cuda.synchronize()\n",
    "    gpu_time = (time.time() - start) * 1000\n",
    "\n",
    "    C_gpu = d_C.copy_to_host()\n",
    "\n",
    "    # CPU timing\n",
    "    cpu_start = time.time()\n",
    "    C_cpu = A @ B\n",
    "    cpu_time = (time.time() - cpu_start) * 1000\n",
    "\n",
    "    print(f\"\\nGPU kernel time: {gpu_time:.4f} ms\")\n",
    "    print(f\"CPU NumPy time: {cpu_time:.4f} ms\")\n",
    "    print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n",
    "    print(f\"Verificación correcta: {np.allclose(C_gpu, C_cpu, atol=1e-3)}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb3368-7fdf-4fd7-822d-52b9f85dcbae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

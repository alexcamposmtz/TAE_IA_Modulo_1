{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0fcaf-0209-42db-acd4-77920ccdcad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ECU3.3 - Matrix Scale (Multiplicación por Escalar)\n",
    "Versión: GPU REAL (Requiere NVIDIA GPU + CUDA Toolkit)\n",
    "Team 6\n",
    "Autor: Alejandro Campos Martínez\n",
    "Curso: TAE en IA - COCYTEN Nayarit\n",
    "Hardware: NVIDIA RTX 4060 Laptop GPU\n",
    "Propósito: Multiplicar cada elemento de una matriz por un escalar usando grid 2D\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import math\n",
    "import time\n",
    "from numba import config\n",
    "\n",
    "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
    "\n",
    "@cuda.jit\n",
    "def matrix_scale_kernel(mat, scalar, out):\n",
    "    \"\"\"\n",
    "    Scale every element: out[row, col] = mat[row, col] * scalar\n",
    "    \"\"\"\n",
    "    row, col = cuda.grid(2)\n",
    "\n",
    "    if row < out.shape[0] and col < out.shape[1]:\n",
    "        out[row, col] = mat[row, col] * scalar\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ECU3.3 - Matrix Scale (GPU REAL)\")\n",
    "    print(\"Autor: Alejandro Campos Martínez - Team 6\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    gpu = cuda.get_current_device()\n",
    "    print(f\"GPU detectada: {gpu.name}\")\n",
    "    print(f\"Compute Capability: {gpu.compute_capability}\")\n",
    "    print(f\"Multiprocessors: {gpu.MULTIPROCESSOR_COUNT}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    rows, cols = 4096, 4096\n",
    "    print(f\"Tamaño de matriz: {rows} x {cols} = {rows*cols:,} elementos\")\n",
    "    print(f\"Memoria: {rows*cols*4/1e6:.2f} MB por matriz\")\n",
    "    \n",
    "    mat = np.random.randn(rows, cols).astype(np.float32)\n",
    "    out = np.zeros_like(mat)\n",
    "    scalar = 2.5\n",
    "    \n",
    "    d_mat = cuda.to_device(mat)\n",
    "    d_out = cuda.to_device(out)\n",
    "\n",
    "    threads_per_block = (16, 16)\n",
    "    blocks_per_grid_x = math.ceil(rows / threads_per_block[0])\n",
    "    blocks_per_grid_y = math.ceil(cols / threads_per_block[1])\n",
    "    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "    \n",
    "    print(f\"Configuración: ({blocks_per_grid_x}, {blocks_per_grid_y}) bloques\")\n",
    "    print(f\"               ({threads_per_block[0]}, {threads_per_block[1]}) threads por bloque\")\n",
    "    print(f\"Total threads: {blocks_per_grid_x * blocks_per_grid_y * threads_per_block[0] * threads_per_block[1]:,}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "    # Warmup\n",
    "    matrix_scale_kernel[blocks_per_grid, threads_per_block](d_mat, scalar, d_out)\n",
    "    cuda.synchronize()\n",
    "\n",
    "    # GPU timing\n",
    "    start = time.time()\n",
    "    matrix_scale_kernel[blocks_per_grid, threads_per_block](d_mat, scalar, d_out)\n",
    "    cuda.synchronize()\n",
    "    gpu_time = (time.time() - start) * 1000\n",
    "\n",
    "    result = d_out.copy_to_host()\n",
    "\n",
    "    # CPU timing\n",
    "    cpu_start = time.time()\n",
    "    expected = mat * scalar\n",
    "    cpu_time = (time.time() - cpu_start) * 1000\n",
    "\n",
    "    print(f\"\\nGPU kernel time: {gpu_time:.3f} ms\")\n",
    "    print(f\"CPU NumPy time: {cpu_time:.3f} ms\")\n",
    "    print(f\"Speedup: {cpu_time / gpu_time:.2f}x\")\n",
    "    print(f\"Verificación correcta: {np.allclose(result, expected)}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb6dc10-30f7-4bfa-967e-d86362d3cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ECU1 - Kernel básico de copia de datos\n",
    "Versión: GPU REAL (Requiere NVIDIA GPU + CUDA Toolkit)\n",
    "Team 6\n",
    "Autor: Alejandro Campos Martínez\n",
    "Curso: TAE en IA - COCYTEN Nayarit\n",
    "Hardware: NVIDIA RTX 6040\n",
    "Propósito: Demostrar estructura básica de CUDA con transferencias de memoria\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "from numba import config\n",
    "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
    "\n",
    "#Pasos para usar CUDA:\n",
    "#Inicializar datos desde la CPU\n",
    "#Transferir de CPU a GPU\n",
    "#Ejecutar Kernel con tamaño de grid/block definido (Hilos)\n",
    "#Transferir resultados de GPU a CPU\n",
    "#Limpiar memoria\n",
    "\n",
    "# CUDA kernel Device\n",
    "@cuda.jit\n",
    "def first_kernel(a, result):\n",
    "    idx = cuda.grid(1)\n",
    "    if idx < a.size:\n",
    "        result[idx] = a[idx]\n",
    "\n",
    "#Host\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ECU1 - Transferencia de Memoria CPU-GPU (GPU REAL)\")\n",
    "    print(\"Autor: Alejandro Campos Martínez - Team 6\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    gpu = cuda.get_current_device()\n",
    "    print(f\"GPU detectada: {gpu.name}\")\n",
    "    print(f\"Compute Capability: {gpu.compute_capability}\")\n",
    "    print(f\"Multiprocessors: {gpu.MULTIPROCESSOR_COUNT}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # 1. Initialize data on CPU\n",
    "    N = 10_000_000\n",
    "    print(f\"Tamaño del array: {N:,} elementos ({N*4/1e6:.2f} MB)\")\n",
    "    a_cpu = np.arange(N, dtype=np.float32)\n",
    "\n",
    "    #======================================\n",
    "    # Computo en CPU\n",
    "    #======================================\n",
    "    start = time.time()\n",
    "    result_cpu = a_cpu.copy()\n",
    "    cpu_time = time.time() - start\n",
    "    print(f\"\\nCPU time: {cpu_time * 1e3:.2f} ms\")\n",
    "\n",
    "    #======================================\n",
    "    # Computo en GPU\n",
    "    #======================================\n",
    "    # Transferencia de CPU a GPU\n",
    "    start = time.time()\n",
    "    a_gpu = cuda.to_device(a_cpu)\n",
    "    result_gpu = cuda.device_array_like(a_cpu) #Reserva Memoria\n",
    "    transfer_in_time = time.time() - start\n",
    "\n",
    "    # Configuración y lanzamiento del kernel\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (N + threads_per_block - 1) // threads_per_block\n",
    "    print(f\"Grid: {blocks_per_grid:,} bloques x {threads_per_block} threads\")\n",
    "    \n",
    "    # Warmup - primera ejecución compila JIT\n",
    "    first_kernel[blocks_per_grid, threads_per_block](a_gpu, result_gpu)\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Medición de tiempo del kernel\n",
    "    start = time.time()\n",
    "    first_kernel[blocks_per_grid, threads_per_block](a_gpu, result_gpu)\n",
    "    cuda.synchronize()\n",
    "    kernel_time = time.time() - start\n",
    "\n",
    "    # Recuperación y medición del tiempo de los resultados\n",
    "    start = time.time()\n",
    "    result_from_gpu = result_gpu.copy_to_host()\n",
    "    cuda.synchronize()\n",
    "    transfer_out_time = time.time() - start\n",
    "\n",
    "    # Reporte\n",
    "    print(f\"\\nGPU transfer to device: {transfer_in_time * 1e3:.2f} ms\")\n",
    "    print(f\"GPU kernel execution: {kernel_time * 1e3:.2f} ms\")\n",
    "    print(f\"GPU transfer to host: {transfer_out_time * 1e3:.2f} ms\")\n",
    "    total_gpu = transfer_in_time + kernel_time + transfer_out_time\n",
    "    print(f\"Total GPU time: {total_gpu * 1e3:.2f} ms\")\n",
    "    \n",
    "    print(f\"\\nSpeedup (kernel only): {cpu_time / kernel_time:.2f}x\")\n",
    "    print(f\"Verificación correcta: {np.allclose(result_cpu, result_from_gpu)}\")\n",
    " \n",
    "\n",
    "    # Liberación de memoria\n",
    "    del a_gpu, result_gpu\n",
    "    cuda.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

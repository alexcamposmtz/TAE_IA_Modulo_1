{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbabbdf5-f7e1-4474-b698-1d84efd9a04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ECU2 - Debug de Indexación de Threads y Bloques (GPU REAL)\n",
      "Autor: Alejandro Campos Martínez - Team 6\n",
      "======================================================================\n",
      "GPU detectada: b'NVIDIA GeForce RTX 4060 Laptop GPU'\n",
      "Compute Capability: (8, 9)\n",
      "Multiprocessors: 24\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Configuración:\n",
      "  Bloques en grid: 2 x 2 = 4 bloques\n",
      "  Threads por bloque: 4 x 1 = 4 threads\n",
      "  Total de threads: 16 threads\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Resultados del kernel:\n",
      "\n",
      "000 | Block[x, y](0 0) =   0 | Thread[x, y] (0 0 ) =   0 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "001 | Block[x, y](0 0) =   0 | Thread[x, y] (1 0 ) =   1 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "002 | Block[x, y](0 0) =   0 | Thread[x, y] (2 0 ) =   2 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "003 | Block[x, y](0 0) =   0 | Thread[x, y] (3 0 ) =   3 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "004 | Block[x, y](1 0) =   1 | Thread[x, y] (0 0 ) =   0 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "005 | Block[x, y](1 0) =   1 | Thread[x, y] (1 0 ) =   1 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "006 | Block[x, y](1 0) =   1 | Thread[x, y] (2 0 ) =   2 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "007 | Block[x, y](1 0) =   1 | Thread[x, y] (3 0 ) =   3 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "008 | Block[x, y](0 1) =   2 | Thread[x, y] (0 0 ) =   0 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "009 | Block[x, y](0 1) =   2 | Thread[x, y] (1 0 ) =   1 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "010 | Block[x, y](0 1) =   2 | Thread[x, y] (2 0 ) =   2 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "011 | Block[x, y](0 1) =   2 | Thread[x, y] (3 0 ) =   3 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "012 | Block[x, y](1 1) =   3 | Thread[x, y] (0 0 ) =   0 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "013 | Block[x, y](1 1) =   3 | Thread[x, y] (1 0 ) =   1 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "014 | Block[x, y](1 1) =   3 | Thread[x, y] (2 0 ) =   2 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "015 | Block[x, y](1 1) =   3 | Thread[x, y] (3 0 ) =   3 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
      "\n",
      "======================================================================\n",
      "Ejecución completada\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xandro/anaconda3/lib/python3.12/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ECU2 - Debug de indexación de Threads y Bloques\n",
    "Versión: GPU REAL (Requiere NVIDIA GPU + CUDA Toolkit)\n",
    "Team 6\n",
    "Autor: Alejandro Campos Martínez\n",
    "Curso: TAE en IA - COCYTEN Nayarit\n",
    "Hardware: NVIDIA RTX 4060 Laptop GPU\n",
    "Propósito: Demostrar cálculo de IDs globales en grid 2D guardando en arrays\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import time\n",
    "from numba import cuda\n",
    "from numba import config\n",
    "\n",
    "config.CUDA_ENABLE_PYNVJITLINK = 1\n",
    "\n",
    "@cuda.jit\n",
    "def whoami_gpu(global_ids, block_ids_x, block_ids_y, thread_ids_x, thread_ids_y, \n",
    "               block_dims_x, block_dims_y, grid_dims_x, grid_dims_y):\n",
    "    \"\"\"\n",
    "    Kernel de debugging para GPU real: Guarda información en arrays\n",
    "    Ya que print() no funciona en GPU real\n",
    "    \"\"\"\n",
    "    # Compute block id in a 2D grid\n",
    "    block_id = (\n",
    "        cuda.blockIdx.x +\n",
    "        cuda.blockIdx.y * cuda.gridDim.x\n",
    "    )\n",
    "\n",
    "    # Threads per block\n",
    "    threads_per_block = (\n",
    "        cuda.blockDim.x * cuda.blockDim.y\n",
    "    )\n",
    "\n",
    "    # Offset of this block\n",
    "    block_offset = block_id * threads_per_block\n",
    "\n",
    "    # Compute thread id inside block\n",
    "    thread_offset = (\n",
    "        cuda.threadIdx.x +\n",
    "        cuda.threadIdx.y * cuda.blockDim.x\n",
    "    )\n",
    "\n",
    "    # Global thread id across all blocks\n",
    "    global_id = block_offset + thread_offset\n",
    "    \n",
    "    # Guardar información en arrays (en lugar de print)\n",
    "    global_ids[global_id] = global_id\n",
    "    block_ids_x[global_id] = cuda.blockIdx.x\n",
    "    block_ids_y[global_id] = cuda.blockIdx.y\n",
    "    thread_ids_x[global_id] = cuda.threadIdx.x\n",
    "    thread_ids_y[global_id] = cuda.threadIdx.y\n",
    "    block_dims_x[global_id] = cuda.blockDim.x\n",
    "    block_dims_y[global_id] = cuda.blockDim.y\n",
    "    grid_dims_x[global_id] = cuda.gridDim.x\n",
    "    grid_dims_y[global_id] = cuda.gridDim.y\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ECU2 - Debug de Indexación de Threads y Bloques (GPU REAL)\")\n",
    "    print(\"Autor: Alejandro Campos Martínez - Team 6\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    gpu = cuda.get_current_device()\n",
    "    print(f\"GPU detectada: {gpu.name}\")\n",
    "    print(f\"Compute Capability: {gpu.compute_capability}\")\n",
    "    print(f\"Multiprocessors: {gpu.MULTIPROCESSOR_COUNT}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Configuración de grid 2D\n",
    "    b_x, b_y = 2, 2  # 2x2 bloques\n",
    "    t_x, t_y = 4, 1  # 4x1 threads por bloque\n",
    "\n",
    "    blocks_per_grid = (b_x, b_y)\n",
    "    threads_per_block = (t_x, t_y)\n",
    "\n",
    "    total_blocks = b_x * b_y\n",
    "    total_threads_per_block = t_x * t_y\n",
    "    total_threads = total_blocks * total_threads_per_block\n",
    "    \n",
    "    print(f\"\\nConfiguración:\")\n",
    "    print(f\"  Bloques en grid: {b_x} x {b_y} = {total_blocks} bloques\")\n",
    "    print(f\"  Threads por bloque: {t_x} x {t_y} = {total_threads_per_block} threads\")\n",
    "    print(f\"  Total de threads: {total_threads} threads\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Crear arrays para guardar información\n",
    "    global_ids = np.zeros(total_threads, dtype=np.int32)\n",
    "    block_ids_x = np.zeros(total_threads, dtype=np.int32)\n",
    "    block_ids_y = np.zeros(total_threads, dtype=np.int32)\n",
    "    thread_ids_x = np.zeros(total_threads, dtype=np.int32)\n",
    "    thread_ids_y = np.zeros(total_threads, dtype=np.int32)\n",
    "    block_dims_x = np.zeros(total_threads, dtype=np.int32)\n",
    "    block_dims_y = np.zeros(total_threads, dtype=np.int32)\n",
    "    grid_dims_x = np.zeros(total_threads, dtype=np.int32)\n",
    "    grid_dims_y = np.zeros(total_threads, dtype=np.int32)\n",
    "    \n",
    "    # Transferir a GPU\n",
    "    d_global_ids = cuda.to_device(global_ids)\n",
    "    d_block_ids_x = cuda.to_device(block_ids_x)\n",
    "    d_block_ids_y = cuda.to_device(block_ids_y)\n",
    "    d_thread_ids_x = cuda.to_device(thread_ids_x)\n",
    "    d_thread_ids_y = cuda.to_device(thread_ids_y)\n",
    "    d_block_dims_x = cuda.to_device(block_dims_x)\n",
    "    d_block_dims_y = cuda.to_device(block_dims_y)\n",
    "    d_grid_dims_x = cuda.to_device(grid_dims_x)\n",
    "    d_grid_dims_y = cuda.to_device(grid_dims_y)\n",
    "\n",
    "    # Launch kernel\n",
    "    whoami_gpu[blocks_per_grid, threads_per_block](\n",
    "        d_global_ids, d_block_ids_x, d_block_ids_y,\n",
    "        d_thread_ids_x, d_thread_ids_y,\n",
    "        d_block_dims_x, d_block_dims_y,\n",
    "        d_grid_dims_x, d_grid_dims_y\n",
    "    )\n",
    "    cuda.synchronize()\n",
    "    \n",
    "    # Copiar resultados\n",
    "    global_ids = d_global_ids.copy_to_host()\n",
    "    block_ids_x = d_block_ids_x.copy_to_host()\n",
    "    block_ids_y = d_block_ids_y.copy_to_host()\n",
    "    thread_ids_x = d_thread_ids_x.copy_to_host()\n",
    "    thread_ids_y = d_thread_ids_y.copy_to_host()\n",
    "    block_dims_x = d_block_dims_x.copy_to_host()\n",
    "    block_dims_y = d_block_dims_y.copy_to_host()\n",
    "    grid_dims_x = d_grid_dims_x.copy_to_host()\n",
    "    grid_dims_y = d_grid_dims_y.copy_to_host()\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(\"\\nResultados del kernel:\\n\")\n",
    "    for i in range(total_threads):\n",
    "        block_id = block_ids_x[i] + block_ids_y[i] * grid_dims_x[i]\n",
    "        thread_offset = thread_ids_x[i] + thread_ids_y[i] * block_dims_x[i]\n",
    "        \n",
    "        print(f\"{global_ids[i]:03d} | \"\n",
    "              f\"Block[x, y]({block_ids_x[i]} {block_ids_y[i]}) = {block_id:3d} | \"\n",
    "              f\"Thread[x, y] ({thread_ids_x[i]} {thread_ids_y[i]} ) = {thread_offset:3d} \"\n",
    "              f\"BlockDim.x {block_dims_x[i]} BlockDim.y {block_dims_y[i]} \"\n",
    "              f\"GridDim.x {grid_dims_x[i]} GridDim.y {grid_dims_y[i]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Ejecución completada\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a528c-9754-44e4-a9d5-03c52c953c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
